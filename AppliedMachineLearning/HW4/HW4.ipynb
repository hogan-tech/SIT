{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hogan Lin\n",
    "# Date: Nov 05th 2024\n",
    "# Github: https://github.com/hogan-tech/SIT/blob/main/AppliedMachineLearning/HW4/HW4.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this programming problem, you will get familiar with building a neural network using\n",
    "backpropagation. \n",
    "2. You will write a program that learns how to recognize the handwritten digits using\n",
    "stochastic gradient descent and the MNIST training data.\n",
    "3. The MNIST database (Modified National Institute of Standards and Technology database is a large\n",
    "database of handwritten digits that is commonly used for training various image processing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "1. Data Loading and Preprocessing: The dataset is successfully loaded using a function that handles IDX files and the images are normalized, an essential step to improve network training.\n",
    "\n",
    "2. One-hot Encoding: Labels are one-hot encoded, allowing for multi-class classification using cross-entropy loss.\n",
    "\n",
    "3. Model Architecture: The network has two hidden layers with 128 and 64 units respectively, followed by an output layer of 10 units. Sigmoid is used as the activation function for hidden layers, and softmax is used for the output layer, appropriate for classification.\n",
    "\n",
    "4. Training: The network uses mini-batch gradient descent with batch size 128 and an epoch loop that shuffles the data each iteration. A learning rate of 0.01 is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Data Acquisition and Visualization (10 pts): \n",
    "In this step, you need to:\n",
    "1. Download the “MNIST” dataset and extract the files. You will get four files with extension .gz (e.g., train-images-idx3-ubyte.gz). You can use the provided function read_idx below to read in the dataset. As its official description, the dataset is split into 60000 training images and 10000 images. The four file corresponds to the training images, training labels, testing images and testing labels. You need to print out their shape to finish this step. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Testing images shape: (10000, 28, 28)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import struct\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "# Provided function to read IDX files, this is HW4 document example code\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# Load the dataset files\n",
    "train_images = read_idx('./train-images-idx3-ubyte.gz')\n",
    "train_labels = read_idx('./train-labels-idx1-ubyte.gz')\n",
    "test_images = read_idx('./t10k-images-idx3-ubyte.gz')\n",
    "test_labels = read_idx('./t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Print shapes of data arrays\n",
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Testing images shape: {test_images.shape}\")\n",
    "print(f\"Testing labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To further understand what the dataset is, you need to use the ‘matplotlib’ library to print out a random data with code plt.imshow together with its label.(5 pts) You will see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a random index to display an image\n",
    "random_index = np.random.randint(0, train_images.shape[0])\n",
    "\n",
    "# Retrieve the image and label for the random index\n",
    "image = train_images[random_index]\n",
    "label = train_labels[random_index]\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')  # Hide the axes for a cleaner look\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Data Preprocessing (10 pts): \n",
    "In this step, you need to:\n",
    "1. Normalize the pixel values of images to be between 0 and 1. (5 pts)\n",
    "2. Convert the labels from categorical data into numerical values using one-hot encoding. (5 pts)\n",
    "hint: you can explore the eye function in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels_onehot:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "test_labels_onehot:  [[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 10\n",
    "train_labels_onehot = np.eye(num_classes)[train_labels]\n",
    "test_labels_onehot = np.eye(num_classes)[test_labels]\n",
    "\n",
    "print(\"train_labels_onehot: \", train_labels_onehot)\n",
    "print(\"test_labels_onehot: \", test_labels_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Network Initialization (10 pts): \n",
    "We will work with a neuron network with two hidden layers, using Sigmoid function as the activation functions for hidden layers and softmax activation function for the output layer. To finish this, you need to:\n",
    "\n",
    "1. Identify the auxiliary input including the Sigmoid function and its derivative and Softmax function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility, 20035085 is my student ID\n",
    "np.random.seed(20035085) \n",
    "\n",
    "# Define Sigmoid and Softmax functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize all the parameters in neural network uniformly. In this network, the input size is 784 dimensions (each input is a 28x28 image, so you have to flatten the data from 2D to 1D). For the two linear hidden layers, we have 128 and 64 neurons respectively. For the output layer, its size will be 10 since there are 10 classes (0-9) in MNIST. To finish this step, you need to initialize the weights and bias in random with a pre-set random seed using Numpy. Please set the seed value = 695. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "input_size = 784\n",
    "hidden_layer1_size = 128\n",
    "hidden_layer2_size = 64\n",
    "output_size = 10\n",
    "\n",
    "# Initialize weights and biases\n",
    "weights1 = np.random.uniform(-0.1, 0.1, (input_size, hidden_layer1_size))\n",
    "bias1 = np.zeros((1, hidden_layer1_size))\n",
    "weights2 = np.random.uniform(-0.1, 0.1, (hidden_layer1_size, hidden_layer2_size))\n",
    "bias2 = np.zeros((1, hidden_layer2_size))\n",
    "weights3 = np.random.uniform(-0.1, 0.1, (hidden_layer2_size, output_size))\n",
    "bias3 = np.zeros((1, output_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Feed Forward (10 pts): \n",
    "In this step, you need to:\n",
    "1. Define a function named feed_forward. Given an input x, it should output the sigmoid of wx+b where w and b indicates the weights and bias defined in step 2. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x):\n",
    "    layer1 = sigmoid(np.dot(x, weights1) + bias1)\n",
    "    layer2 = sigmoid(np.dot(layer1, weights2) + bias2)\n",
    "    output_layer = softmax(np.dot(layer2, weights3) + bias3)\n",
    "    return layer1, layer2, output_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Back Propagation (15 pts): \n",
    "In this step, you need to implement the back propagation:\n",
    "1. You need to compute the loss for the output layer first. Here, we use categorical cross entropy\n",
    "loss function given below for multi-class classification problem. (5 pts) Note, to achieve this, you\n",
    "need to first encode the categorical labels as numerical values using one-hot encoding finished\n",
    "in step 2. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code example from the HW4 document\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    # Number of samples\n",
    "    n_samples = y_true.shape[0]\n",
    "    # Clip predictions to avoid log(0) errors\n",
    "    y_pred_clipped = np.clip(y_pred, 1e-12, 1 - 1e-12)\n",
    "    # Compute cross-entropy loss\n",
    "    return -np.sum(y_true * np.log(y_pred_clipped)) / n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x, y_true, layer1, layer2, output_layer):\n",
    "    # Number of samples\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # Calculate error at output layer\n",
    "    d_output = output_layer - y_true  # (output_layer - y_true) is the derivative of the cross-entropy loss\n",
    "    grad_weights3 = np.dot(layer2.T, d_output) / n_samples\n",
    "    grad_bias3 = np.sum(d_output, axis=0, keepdims=True) / n_samples\n",
    "\n",
    "    # Calculate error for second hidden layer\n",
    "    d_layer2 = np.dot(d_output, weights3.T) * sigmoid_derivative(layer2)\n",
    "    grad_weights2 = np.dot(layer1.T, d_layer2) / n_samples\n",
    "    grad_bias2 = np.sum(d_layer2, axis=0, keepdims=True) / n_samples\n",
    "\n",
    "    # Calculate error for first hidden layer\n",
    "    d_layer1 = np.dot(d_layer2, weights2.T) * sigmoid_derivative(layer1)\n",
    "    grad_weights1 = np.dot(x.T, d_layer1) / n_samples\n",
    "    grad_bias1 = np.sum(d_layer1, axis=0, keepdims=True) / n_samples\n",
    "\n",
    "    # Return the gradients\n",
    "    return grad_weights1, grad_bias1, grad_weights2, grad_bias2, grad_weights3, grad_bias3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Model Training (15 pts): \n",
    "In this step, you need to:\n",
    "1. Use mini-batch gradient descent to update the parameters including weights and bias. Notice\n",
    "that a complete training round consists of a feed forward process, back propagation and\n",
    "parameter update. Define the batch size = 128 and epoch = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Mini-Batch Gradient Descent: Optimizing Machine Learning: \n",
    "https://medium.com/@juanc.olamendy/mini-batch-gradient-descent-optimizing-machine-learning-98ef238c5225\n",
    "\n",
    "Training in mini-batches: Stochastic gradient descent:\n",
    "https://github.com/parrt/msds621/blob/master/notebooks/deep-learning/7.SGD-minibatch-mnist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.3040\n",
      "Epoch 2/100, Loss: 2.3041\n",
      "Epoch 3/100, Loss: 2.3047\n",
      "Epoch 4/100, Loss: 2.3038\n",
      "Epoch 5/100, Loss: 2.3039\n",
      "Epoch 6/100, Loss: 2.3039\n",
      "Epoch 7/100, Loss: 2.3052\n",
      "Epoch 8/100, Loss: 2.3043\n",
      "Epoch 9/100, Loss: 2.3031\n",
      "Epoch 10/100, Loss: 2.3034\n",
      "Epoch 11/100, Loss: 2.3038\n",
      "Epoch 12/100, Loss: 2.3054\n",
      "Epoch 13/100, Loss: 2.3035\n",
      "Epoch 14/100, Loss: 2.3044\n",
      "Epoch 15/100, Loss: 2.3046\n",
      "Epoch 16/100, Loss: 2.3042\n",
      "Epoch 17/100, Loss: 2.3038\n",
      "Epoch 18/100, Loss: 2.3040\n",
      "Epoch 19/100, Loss: 2.3048\n",
      "Epoch 20/100, Loss: 2.3049\n",
      "Epoch 21/100, Loss: 2.3041\n",
      "Epoch 22/100, Loss: 2.3036\n",
      "Epoch 23/100, Loss: 2.3048\n",
      "Epoch 24/100, Loss: 2.3043\n",
      "Epoch 25/100, Loss: 2.3042\n",
      "Epoch 26/100, Loss: 2.3056\n",
      "Epoch 27/100, Loss: 2.3033\n",
      "Epoch 28/100, Loss: 2.3049\n",
      "Epoch 29/100, Loss: 2.3039\n",
      "Epoch 30/100, Loss: 2.3030\n",
      "Epoch 31/100, Loss: 2.3044\n",
      "Epoch 32/100, Loss: 2.3045\n",
      "Epoch 33/100, Loss: 2.3048\n",
      "Epoch 34/100, Loss: 2.3047\n",
      "Epoch 35/100, Loss: 2.3057\n",
      "Epoch 36/100, Loss: 2.3043\n",
      "Epoch 37/100, Loss: 2.3041\n",
      "Epoch 38/100, Loss: 2.3036\n",
      "Epoch 39/100, Loss: 2.3040\n",
      "Epoch 40/100, Loss: 2.3042\n",
      "Epoch 41/100, Loss: 2.3046\n",
      "Epoch 42/100, Loss: 2.3051\n",
      "Epoch 43/100, Loss: 2.3045\n",
      "Epoch 44/100, Loss: 2.3036\n",
      "Epoch 45/100, Loss: 2.3033\n",
      "Epoch 46/100, Loss: 2.3056\n",
      "Epoch 47/100, Loss: 2.3036\n",
      "Epoch 48/100, Loss: 2.3050\n",
      "Epoch 49/100, Loss: 2.3045\n",
      "Epoch 50/100, Loss: 2.3049\n",
      "Epoch 51/100, Loss: 2.3042\n",
      "Epoch 52/100, Loss: 2.3041\n",
      "Epoch 53/100, Loss: 2.3042\n",
      "Epoch 54/100, Loss: 2.3038\n",
      "Epoch 55/100, Loss: 2.3045\n",
      "Epoch 56/100, Loss: 2.3046\n",
      "Epoch 57/100, Loss: 2.3043\n",
      "Epoch 58/100, Loss: 2.3038\n",
      "Epoch 59/100, Loss: 2.3047\n",
      "Epoch 60/100, Loss: 2.3044\n",
      "Epoch 61/100, Loss: 2.3057\n",
      "Epoch 62/100, Loss: 2.3043\n",
      "Epoch 63/100, Loss: 2.3039\n",
      "Epoch 64/100, Loss: 2.3042\n",
      "Epoch 65/100, Loss: 2.3039\n",
      "Epoch 66/100, Loss: 2.3045\n",
      "Epoch 67/100, Loss: 2.3049\n",
      "Epoch 68/100, Loss: 2.3049\n",
      "Epoch 69/100, Loss: 2.3041\n",
      "Epoch 70/100, Loss: 2.3027\n",
      "Epoch 71/100, Loss: 2.3036\n",
      "Epoch 72/100, Loss: 2.3042\n",
      "Epoch 73/100, Loss: 2.3053\n",
      "Epoch 74/100, Loss: 2.3043\n",
      "Epoch 75/100, Loss: 2.3053\n",
      "Epoch 76/100, Loss: 2.3031\n",
      "Epoch 77/100, Loss: 2.3055\n",
      "Epoch 78/100, Loss: 2.3032\n",
      "Epoch 79/100, Loss: 2.3042\n",
      "Epoch 80/100, Loss: 2.3049\n",
      "Epoch 81/100, Loss: 2.3043\n",
      "Epoch 82/100, Loss: 2.3036\n",
      "Epoch 83/100, Loss: 2.3033\n",
      "Epoch 84/100, Loss: 2.3040\n",
      "Epoch 85/100, Loss: 2.3040\n",
      "Epoch 86/100, Loss: 2.3038\n",
      "Epoch 87/100, Loss: 2.3052\n",
      "Epoch 88/100, Loss: 2.3038\n",
      "Epoch 89/100, Loss: 2.3041\n",
      "Epoch 90/100, Loss: 2.3048\n",
      "Epoch 91/100, Loss: 2.3050\n",
      "Epoch 92/100, Loss: 2.3051\n",
      "Epoch 93/100, Loss: 2.3049\n",
      "Epoch 94/100, Loss: 2.3034\n",
      "Epoch 95/100, Loss: 2.3027\n",
      "Epoch 96/100, Loss: 2.3049\n",
      "Epoch 97/100, Loss: 2.3034\n",
      "Epoch 98/100, Loss: 2.3045\n",
      "Epoch 99/100, Loss: 2.3053\n",
      "Epoch 100/100, Loss: 2.3037\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the data\n",
    "    indices = np.arange(train_images.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    train_images = train_images[indices]\n",
    "    train_labels = train_labels[indices]\n",
    "\n",
    "    train_images = train_images.reshape(-1, 784)\n",
    "    test_images = test_images.reshape(-1, 784)\n",
    "    \n",
    "    # # Mini-batch gradient descent\n",
    "    for i in range(0, train_images.shape[0], batch_size):\n",
    "        x_batch = train_images[i:i+batch_size]\n",
    "        y_batch = train_labels_onehot[i:i+batch_size]\n",
    "\n",
    "        # Feed forward\n",
    "        layer1, layer2, output_layer = feed_forward(x_batch)\n",
    "\n",
    "        # Compute loss (optional, for monitoring training)\n",
    "        loss = categorical_crossentropy(y_batch, output_layer)\n",
    "\n",
    "        # Backpropagation to calculate gradients\n",
    "        grad_weights1, grad_bias1, grad_weights2, grad_bias2, grad_weights3, grad_bias3 = backpropagation(\n",
    "            x_batch, y_batch, layer1, layer2, output_layer\n",
    "        )\n",
    "\n",
    "        # Update parameters\n",
    "        weights1 -= learning_rate * grad_weights1\n",
    "        bias1 -= learning_rate * grad_bias1\n",
    "        weights2 -= learning_rate * grad_weights2\n",
    "        bias2 -= learning_rate * grad_bias2\n",
    "        weights3 -= learning_rate * grad_weights3\n",
    "        bias3 -= learning_rate * grad_bias3\n",
    "\n",
    "    # Optionally, print the loss to track the training progress\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 Model Evaluation (10 pts): \n",
    "In this step, you need to:\n",
    "1. Use your trained neural network to predict the labels of the test dataset and compute the\n",
    "accuracy on the test dataset. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 13.01%\n"
     ]
    }
   ],
   "source": [
    "def predict(x):\n",
    "    # Forward pass through the trained network\n",
    "    layer1 = sigmoid(np.dot(x, weights1) + bias1)\n",
    "    layer2 = sigmoid(np.dot(layer1, weights2) + bias2)\n",
    "    output_layer = softmax(np.dot(layer2, weights3) + bias3)\n",
    "    return np.argmax(output_layer, axis=1)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "# Get predictions for test images\n",
    "y_test_pred = predict(test_images)\n",
    "# Convert one-hot encoded test labels back to single integers\n",
    "y_test_true = test_labels \n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = compute_accuracy(y_test_true, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A test accuracy of 13.01% indicates that the model correctly classifies the test images only about 13% of the time, which is very close to random guessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot some of the misclassified images with their predicted and true labels. (5 pts) This probably\n",
    "can give you some insights into why these images are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify misclassified images\n",
    "misclassified_indices = np.where(y_test_pred != y_test_true)[0]\n",
    "\n",
    "# Plot a few misclassified images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, idx in enumerate(misclassified_indices[:9]):  # Display up to 9 misclassified images\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(test_images[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"True: {y_test_true[idx]}, Pred: {y_test_pred[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "1. Activation Function Choice: Sigmoid activation can lead to vanishing gradients, especially in deeper networks. ReLU (Rectified Linear Unit) is often more effective for hidden layers as it reduces gradient issues and accelerates convergence.\n",
    "\n",
    "2. Loss Behavior: The loss values shared indicate that the model may be underfitting, as it oscillates around 2.3, close to random guessing (e.g., 1/10 for ten classes). This suggests that the model isn't learning effectively with the current setup, potentially due to activation function choice, weight initialization, or learning rate.\n",
    "\n",
    "3. Accuracy Calculation: Implementing accuracy as a metric for the test set is effective for gauging generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights \n",
    "\n",
    "1. Consider Activation Adjustments: Switching from Sigmoid to ReLU in the hidden layers could help with gradient flow and overall convergence, particularly given the depth of your network.\n",
    "\n",
    "2. Evaluate Weight Initialization: Initializing weights with small values close to zero could cause gradient issues. Using a more advanced initialization, like He or Xavier initialization, might improve training stability and speed.\n",
    "\n",
    "3. Learning Rate Tuning: If the loss remains unchanged, we might explore a slightly higher or lower learning rate. Using learning rate decay can also prevent oscillations in later stages of training.\n",
    "\n",
    "4. Accuracy Monitoring per Epoch: Adding a quick accuracy calculation for the training set per epoch can offer more insight into whether the model is effectively learning the patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve\n",
    "\n",
    "Although we do not need to improve the accurancy, but I did the Keras CNN Mnist several years ago, here is the quick implementation, and the accuracy improve from 13.04% to 98%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8501 - loss: 0.5114 - val_accuracy: 0.9776 - val_loss: 0.0748\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9797 - loss: 0.0668 - val_accuracy: 0.9840 - val_loss: 0.0508\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.0453 - val_accuracy: 0.9879 - val_loss: 0.0370\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9902 - loss: 0.0335 - val_accuracy: 0.9903 - val_loss: 0.0304\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0244 - val_accuracy: 0.9895 - val_loss: 0.0339\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9898 - val_loss: 0.0309\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.9894 - val_loss: 0.0339\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.9915 - val_loss: 0.0302\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9923 - val_loss: 0.0258\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 0.9915 - val_loss: 0.0279\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0388\n",
      "Test Accuracy: 99.15%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import gzip\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load IDX files (this remains the same as before)\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# Load dataset\n",
    "train_images = read_idx('./train-images-idx3-ubyte.gz')\n",
    "train_labels = read_idx('./train-labels-idx1-ubyte.gz')\n",
    "test_images = read_idx('./t10k-images-idx3-ubyte.gz')\n",
    "test_labels = read_idx('./t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Normalize and reshape images to match CNN input (add channel dimension)\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
